{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_data_p(p: str, datasets=[], output_dir='results', test=True):\n",
    "    \"\"\"\n",
    "    Collects data from multiple datasets and methods for a specific missingness percentage,\n",
    "    and formats it into a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        p (str): The missingness percentage (e.g., \"0.0\").\n",
    "        datasets (list): List of dataset names to analyze.\n",
    "        output_dir (str): The base directory where results are saved.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing formatted results for each method and imputation.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import re\n",
    "    \n",
    "    if not datasets:\n",
    "        # If no datasets are specified, get all available datasets from the directory\n",
    "        datasets = [d for d in os.listdir(output_dir) if os.path.isdir(os.path.join(output_dir, d))]\n",
    "    \n",
    "    # Initialize an empty list to store data rows\n",
    "    data_rows = []\n",
    "    \n",
    "    # First pass: collect all methods and imputations across all datasets\n",
    "    all_method_imputation_pairs = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        dataset_dir = os.path.join(output_dir, dataset)\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            print(f\"Warning: Dataset directory {dataset_dir} not found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Get all method directories for this dataset\n",
    "        method_dirs = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "        \n",
    "        for method in method_dirs:\n",
    "            method_dir = os.path.join(dataset_dir, method)\n",
    "            \n",
    "            for imputation in os.listdir(method_dir):\n",
    "                \n",
    "            \n",
    "                method_imputation_pair = (method, imputation)\n",
    "                if method_imputation_pair not in all_method_imputation_pairs:\n",
    "                    all_method_imputation_pairs.append(method_imputation_pair)\n",
    "    # print(all_method_imputation_pairs)\n",
    "\n",
    "    # Second pass: collect results for each method/imputation pair across all datasets\n",
    "    for method, imputation in all_method_imputation_pairs:\n",
    "        row = {\n",
    "            'method': method,\n",
    "            'imputation': imputation\n",
    "        }\n",
    "        \n",
    "        # Collect results for each dataset\n",
    "        for dataset in datasets:\n",
    "            dataset_dir = os.path.join(output_dir, dataset)\n",
    "            if not os.path.exists(dataset_dir):\n",
    "                print(f\"{method_dir} not exits!\")\n",
    "                # Dataset doesn't exist, fill with N/A\n",
    "                row[f\"{dataset}_PEHE\"] = \"N/A\"\n",
    "                row[f\"{dataset}_MAE\"] = \"N/A\"\n",
    "                continue\n",
    "                \n",
    "            method_dir = os.path.join(dataset_dir, method)\n",
    "            if not os.path.exists(method_dir):\n",
    "                # Method doesn't exist for this dataset, fill with N/A\n",
    "                row[f\"{dataset}_PEHE\"] = \"N/A\"\n",
    "                row[f\"{dataset}_MAE\"] = \"N/A\"\n",
    "                continue\n",
    "            \n",
    "            imputation_dir = os.path.join(method_dir, imputation)\n",
    "            train_test_flag = \"test\" if test else \"train\"\n",
    "            # Get all result files for this method with the specified p value\n",
    "            results_files = [f for f in os.listdir(imputation_dir) \n",
    "                        if f.startswith(f\"p={p}_\") and f.endswith(f\"_{train_test_flag}_results.json\")]\n",
    "            \n",
    "            # print(results_files)\n",
    "            effect_pehe_values = []\n",
    "            effect_mae_values = []\n",
    "            \n",
    "            # Collect metrics from all matching files\n",
    "            for file in results_files:\n",
    "                file_path = os.path.join(method_dir, imputation, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        results = json.load(f)\n",
    "                        if 'effect_pehe' in results:\n",
    "                            effect_pehe_values.append(results['effect_pehe'])\n",
    "                        if 'effect_mae' in results:\n",
    "                            effect_mae_values.append(results['effect_mae'])\n",
    "                except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "                    print(f\"Warning: Error reading file {file_path}: {e}\")\n",
    "            # print(\"PHHE\", effect_pehe_values)\n",
    "            # print(\"MAE\", effect_mae_values)\n",
    "            # Format mean and std for each metric\n",
    "            if effect_pehe_values:\n",
    "                mean_pehe = np.mean(effect_pehe_values)\n",
    "                std_pehe = np.std(effect_pehe_values)\n",
    "                row[f\"{dataset}_PEHE\"] = f\"{mean_pehe:.2f} ± {std_pehe:.2f}\"\n",
    "            else:\n",
    "                row[f\"{dataset}_PEHE\"] = \"N/A\"\n",
    "            \n",
    "            if effect_mae_values:\n",
    "                mean_mae = np.mean(effect_mae_values)\n",
    "                std_mae = np.std(effect_mae_values)\n",
    "                row[f\"{dataset}_MAE\"] = f\"{mean_mae:.2f} ± {std_mae:.2f}\"\n",
    "            else:\n",
    "                row[f\"{dataset}_MAE\"] = \"N/A\"\n",
    "        # print(row)\n",
    "        data_rows.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    # print(df)\n",
    "    \n",
    "    # Sort the DataFrame by method and imputation\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(by=['method', 'imputation'])\n",
    "    \n",
    "    # # Reorder columns to match the required order\n",
    "    # if not df.empty:\n",
    "    #     columns = ['method', 'imputation']\n",
    "    #     for dataset in datasets:\n",
    "    #         columns.extend([f\"{dataset}_PEHE\", f\"{dataset}_AME\"])\n",
    "        \n",
    "    #     # Make sure all columns exist before reordering\n",
    "    #     existing_columns = [col for col in columns if col in df.columns]\n",
    "    #     df = df[existing_columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def display_results(p, datasets=[\"Syn\", \"Youtube\"]):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Set display options to show all rows and columns\n",
    "    pd.set_option('display.max_rows', None)  # Show all rows\n",
    "    pd.set_option('display.max_columns', None)  # Show all columns\n",
    "    pd.set_option('display.width', None)  # Use the full width of the notebook cell\n",
    "    pd.set_option('display.max_colwidth', None)  # Show full content of each column\n",
    "    \n",
    "    # Example: Display the DataFrame created by collect_data_p\n",
    "    df = collect_data_p(p, datasets=datasets) #, \"AMZS\", \"Flickr\"])\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58520f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset directory results/Syn not found. Skipping.\n",
      "Warning: Dataset directory results/Youtube not found. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset directory results/Syn not found. Skipping.\n",
      "Warning: Dataset directory results/Youtube not found. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset directory results/Syn not found. Skipping.\n",
      "Warning: Dataset directory results/Youtube not found. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dataset directory results/Syn not found. Skipping.\n",
      "Warning: Dataset directory results/Youtube not found. Skipping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_results(p='0.0')\n",
    "display_results(p='0.1')\n",
    "display_results(p='0.3')\n",
    "display_results(p='0.5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
