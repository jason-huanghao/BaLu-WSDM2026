{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992e270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test_basic_functionality...\n",
      "✓ test_basic_functionality passed\n",
      "Running test_complex_mapping...\n",
      "✓ test_complex_mapping passed\n",
      "Running test_device_consistency...\n",
      "✓ test_device_consistency passed\n",
      "Running test_different_dtypes...\n",
      "✓ test_different_dtypes passed\n",
      "Running test_edge_values_preserved...\n",
      "✓ test_edge_values_preserved passed\n",
      "Running test_input_validation...\n",
      "✓ test_input_validation passed\n",
      "Running test_keep_all_nodes...\n",
      "✓ test_keep_all_nodes passed\n",
      "Running test_keep_no_nodes...\n",
      "✓ test_keep_no_nodes passed\n",
      "Running test_no_edges...\n",
      "✓ test_no_edges passed\n",
      "Running test_single_node...\n",
      "✓ test_single_node passed\n",
      "Running test_single_node_filtered_out...\n",
      "✓ test_single_node_filtered_out passed\n",
      "\n",
      "All tests completed!\n",
      "\n",
      "==================================================\n",
      "EXAMPLE USAGE:\n",
      "==================================================\n",
      "Original adjacency matrix:\n",
      "tensor([[0., 1., 0., 0.],\n",
      "        [2., 0., 5., 0.],\n",
      "        [0., 0., 0., 3.],\n",
      "        [0., 0., 4., 0.]])\n",
      "\n",
      "Keep mask: tensor([ True, False,  True,  True])\n",
      "Keeping nodes: [0, 2, 3]\n",
      "\n",
      "Filtered adjacency matrix (size torch.Size([3, 3])):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 3.],\n",
      "        [0., 4., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def filter_and_remap_edges(adj_matrix, keep_mask):\n",
    "    \"\"\"Improved version of the filter function\"\"\"\n",
    "    keep_mask = keep_mask.bool()\n",
    "    adj_matrix = adj_matrix.coalesce()\n",
    "    \n",
    "    valid_indices = torch.where(keep_mask)[0]\n",
    "    num_valid_nodes = len(valid_indices)\n",
    "    \n",
    "    mapping = torch.full((len(keep_mask),), -1, dtype=torch.long, device=keep_mask.device)\n",
    "    mapping[valid_indices] = torch.arange(num_valid_nodes, device=keep_mask.device)\n",
    "    \n",
    "    adj_indices = adj_matrix.indices()\n",
    "    adj_values = adj_matrix.values()\n",
    "    \n",
    "    valid_edges_mask = keep_mask[adj_indices[0]] & keep_mask[adj_indices[1]]\n",
    "    \n",
    "    if valid_edges_mask.sum() == 0:\n",
    "        filtered_indices = torch.empty((2, 0), dtype=torch.long, device=keep_mask.device)\n",
    "        filtered_values = torch.empty(0, dtype=adj_values.dtype, device=keep_mask.device)\n",
    "    else:\n",
    "        filtered_indices = adj_indices[:, valid_edges_mask]\n",
    "        filtered_values = adj_values[valid_edges_mask]\n",
    "        filtered_indices[0] = mapping[filtered_indices[0]]\n",
    "        filtered_indices[1] = mapping[filtered_indices[1]]\n",
    "    \n",
    "    filtered_adj = torch.sparse_coo_tensor(\n",
    "        indices=filtered_indices,\n",
    "        values=filtered_values,\n",
    "        size=(num_valid_nodes, num_valid_nodes),\n",
    "        dtype=adj_matrix.dtype,\n",
    "        device=adj_matrix.device\n",
    "    )\n",
    "    \n",
    "    return filtered_adj\n",
    "\n",
    "\n",
    "class TestFilterAndRemapEdges:\n",
    "    \n",
    "    def test_basic_functionality(self):\n",
    "        \"\"\"Test basic filtering and remapping\"\"\"\n",
    "        # Create a 4x4 adjacency matrix\n",
    "        indices = torch.tensor([[0, 1, 2, 3, 1], [1, 0, 3, 2, 2]])\n",
    "        values = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (4, 4))\n",
    "        \n",
    "        # Keep nodes 0, 2, 3 (filter out node 1)\n",
    "        keep_mask = torch.tensor([True, False, True, True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        # Expected: nodes 0->1, 2->3, 3->2 become 0->?, 1->2, 2->1\n",
    "        # But edges involving node 1 should be filtered out\n",
    "        # So we should have: 2->3 becomes 1->2, and 3->2 becomes 2->1\n",
    "        \n",
    "        assert result.size() == (3, 3)  # 3 remaining nodes\n",
    "        result_dense = result.to_dense()\n",
    "        \n",
    "        # Verify specific edges exist\n",
    "        assert result_dense[1, 2] == 3.0  # edge 2->3 mapped to 1->2\n",
    "        assert result_dense[2, 1] == 4.0  # edge 3->2 mapped to 2->1\n",
    "        \n",
    "    def test_keep_all_nodes(self):\n",
    "        \"\"\"Test when all nodes are kept\"\"\"\n",
    "        indices = torch.tensor([[0, 1, 2], [1, 2, 0]])\n",
    "        values = torch.tensor([1.0, 2.0, 3.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (3, 3))\n",
    "        \n",
    "        keep_mask = torch.tensor([True, True, True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        # Should be identical to original\n",
    "        assert result.size() == (3, 3)\n",
    "        assert torch.allclose(result.to_dense(), adj_matrix.to_dense())\n",
    "        \n",
    "    def test_keep_no_nodes(self):\n",
    "        \"\"\"Test when no nodes are kept\"\"\"\n",
    "        indices = torch.tensor([[0, 1], [1, 0]])\n",
    "        values = torch.tensor([1.0, 2.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (2, 2))\n",
    "        \n",
    "        keep_mask = torch.tensor([False, False])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        assert result.size() == (0, 0)\n",
    "        assert result._nnz() == 0\n",
    "        \n",
    "    def test_no_edges(self):\n",
    "        \"\"\"Test with no edges in the adjacency matrix\"\"\"\n",
    "        indices = torch.empty((2, 0), dtype=torch.long)\n",
    "        values = torch.empty(0, dtype=torch.float)\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (4, 4))\n",
    "        \n",
    "        keep_mask = torch.tensor([True, False, True, True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        assert result.size() == (3, 3)\n",
    "        assert result._nnz() == 0\n",
    "        \n",
    "    def test_single_node(self):\n",
    "        \"\"\"Test with single node\"\"\"\n",
    "        indices = torch.tensor([[0], [0]])\n",
    "        values = torch.tensor([5.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (1, 1))\n",
    "        \n",
    "        keep_mask = torch.tensor([True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        assert result.size() == (1, 1)\n",
    "        assert result.to_dense()[0, 0] == 5.0\n",
    "        \n",
    "    def test_single_node_filtered_out(self):\n",
    "        \"\"\"Test with single node that gets filtered out\"\"\"\n",
    "        indices = torch.tensor([[0], [0]])\n",
    "        values = torch.tensor([5.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (1, 1))\n",
    "        \n",
    "        keep_mask = torch.tensor([False])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        assert result.size() == (0, 0)\n",
    "        assert result._nnz() == 0\n",
    "        \n",
    "    def test_edge_values_preserved(self):\n",
    "        \"\"\"Test that edge values are correctly preserved\"\"\"\n",
    "        indices = torch.tensor([[0, 1, 2], [2, 0, 1]])\n",
    "        values = torch.tensor([10.5, 20.3, 30.7])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (3, 3))\n",
    "        \n",
    "        keep_mask = torch.tensor([True, True, True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        # Check that values are preserved\n",
    "        result_coo = result.coalesce()\n",
    "        result_values = result_coo.values()\n",
    "        \n",
    "        # Sort both to compare (order might change)\n",
    "        orig_sorted = torch.sort(values)[0]\n",
    "        result_sorted = torch.sort(result_values)[0]\n",
    "        \n",
    "        assert torch.allclose(orig_sorted, result_sorted)\n",
    "        \n",
    "    def test_different_dtypes(self):\n",
    "        \"\"\"Test with different data types\"\"\"\n",
    "        indices = torch.tensor([[0, 1], [1, 0]])\n",
    "        \n",
    "        # Test int values\n",
    "        values_int = torch.tensor([1, 2], dtype=torch.int32)\n",
    "        adj_matrix_int = torch.sparse_coo_tensor(indices, values_int, (2, 2))\n",
    "        keep_mask = torch.tensor([True, True])\n",
    "        \n",
    "        result_int = filter_and_remap_edges(adj_matrix_int, keep_mask)\n",
    "        assert result_int.dtype == torch.int32\n",
    "        \n",
    "        # Test double values\n",
    "        values_double = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
    "        adj_matrix_double = torch.sparse_coo_tensor(indices, values_double, (2, 2))\n",
    "        \n",
    "        result_double = filter_and_remap_edges(adj_matrix_double, keep_mask)\n",
    "        assert result_double.dtype == torch.float64\n",
    "        \n",
    "    def test_device_consistency(self):\n",
    "        \"\"\"Test that device is preserved\"\"\"\n",
    "        indices = torch.tensor([[0, 1], [1, 0]])\n",
    "        values = torch.tensor([1.0, 2.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (2, 2))\n",
    "        keep_mask = torch.tensor([True, False])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        assert result.device == adj_matrix.device\n",
    "        assert result.device == keep_mask.device\n",
    "        \n",
    "    def test_complex_mapping(self):\n",
    "        \"\"\"Test more complex node mapping scenario\"\"\"\n",
    "        # 5 nodes, keep nodes 1, 3, 4 (indices 0, 2, 3, 4 get filtered out)\n",
    "        indices = torch.tensor([[0, 1, 2, 3, 4, 1, 3], [1, 3, 1, 4, 2, 4, 1]])\n",
    "        values = torch.tensor([1., 2., 3., 4., 5., 6., 7.])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (5, 5))\n",
    "        \n",
    "        keep_mask = torch.tensor([False, True, False, True, True])\n",
    "        \n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "        \n",
    "        # Remaining nodes: 1, 3, 4 -> mapped to 0, 1, 2\n",
    "        # Edges that should remain:\n",
    "        # 1->3 (value 2) -> 0->1\n",
    "        # 3->4 (value 4) -> 1->2  \n",
    "        # 1->4 (value 6) -> 0->2\n",
    "        # 3->1 (value 7) -> 1->0\n",
    "        \n",
    "        assert result.size() == (3, 3)\n",
    "        result_dense = result.to_dense()\n",
    "        \n",
    "        assert result_dense[0, 1] == 2.0  # 1->3 became 0->1\n",
    "        assert result_dense[1, 2] == 4.0  # 3->4 became 1->2\n",
    "        assert result_dense[0, 2] == 6.0  # 1->4 became 0->2\n",
    "        assert result_dense[1, 0] == 7.0  # 3->1 became 1->0\n",
    "        \n",
    "    def test_input_validation(self):\n",
    "        \"\"\"Test input edge cases and validation\"\"\"\n",
    "        indices = torch.tensor([[0, 1], [1, 0]])\n",
    "        values = torch.tensor([1.0, 2.0])\n",
    "        adj_matrix = torch.sparse_coo_tensor(indices, values, (2, 2))\n",
    "        \n",
    "        # Test with non-boolean mask (should be converted)\n",
    "        keep_mask_int = torch.tensor([1, 0], dtype=torch.int)\n",
    "        result = filter_and_remap_edges(adj_matrix, keep_mask_int)\n",
    "        assert result.size() == (1, 1)\n",
    "        \n",
    "    def run_all_tests(self):\n",
    "        \"\"\"Run all tests\"\"\"\n",
    "        test_methods = [method for method in dir(self) if method.startswith('test_')]\n",
    "        \n",
    "        for test_method in test_methods:\n",
    "            print(f\"Running {test_method}...\")\n",
    "            try:\n",
    "                getattr(self, test_method)()\n",
    "                print(f\"✓ {test_method} passed\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {test_method} failed: {e}\")\n",
    "                raise\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Run all tests\n",
    "    tester = TestFilterAndRemapEdges()\n",
    "    tester.run_all_tests()\n",
    "    print(\"\\nAll tests completed!\")\n",
    "    \n",
    "    # Example of individual test\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXAMPLE USAGE:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create sample data\n",
    "    indices = torch.tensor([[0, 1, 2, 3, 1], [1, 0, 3, 2, 2]])\n",
    "    values = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "    adj_matrix = torch.sparse_coo_tensor(indices, values, (4, 4))\n",
    "    \n",
    "    print(\"Original adjacency matrix:\")\n",
    "    print(adj_matrix.to_dense())\n",
    "    \n",
    "    keep_mask = torch.tensor([True, False, True, True])\n",
    "    print(f\"\\nKeep mask: {keep_mask}\")\n",
    "    print(f\"Keeping nodes: {torch.where(keep_mask)[0].tolist()}\")\n",
    "    \n",
    "    result = filter_and_remap_edges(adj_matrix, keep_mask)\n",
    "    print(f\"\\nFiltered adjacency matrix (size {result.size()}):\")\n",
    "    print(result.to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_frequency_weighted_adj(rel_edge_index):\n",
    "    \"\"\"Original function from the user\"\"\"\n",
    "    num_nodes = rel_edge_index.max().item() + 1\n",
    "    # Count occurrences of each edge\n",
    "    edge_counts = defaultdict(int)\n",
    "    \n",
    "    for i in range(rel_edge_index.size(1)):\n",
    "        src = rel_edge_index[0, i].item()\n",
    "        dst = rel_edge_index[1, i].item()\n",
    "        edge_counts[(src, dst)] += 1\n",
    "    \n",
    "    # Create indices and values for sparse tensor\n",
    "    indices = []\n",
    "    values = []\n",
    "    \n",
    "    for (src, dst), count in edge_counts.items():\n",
    "        indices.append([src, dst])\n",
    "        values.append(float(count))\n",
    "    \n",
    "    if indices:\n",
    "        indices = torch.tensor(indices).t()  # Shape: [2, num_unique_edges]\n",
    "        values = torch.tensor(values)\n",
    "    else:\n",
    "        indices = torch.empty((2, 0), dtype=torch.long)\n",
    "        values = torch.empty(0)\n",
    "    \n",
    "    adj = torch.sparse_coo_tensor(\n",
    "        indices=indices,\n",
    "        values=values,\n",
    "        size=(num_nodes, num_nodes)\n",
    "    )\n",
    "    \n",
    "    return adj\n",
    "\n",
    "def filter_and_remap_edges_improved(adj_matrix, keep_mask):\n",
    "    \"\"\"Improved version of the filter function\"\"\"\n",
    "    keep_mask = keep_mask.bool()\n",
    "    adj_matrix = adj_matrix.coalesce()\n",
    "    \n",
    "    valid_indices = torch.where(keep_mask)[0]\n",
    "    num_valid_nodes = len(valid_indices)\n",
    "    \n",
    "    mapping = torch.full((len(keep_mask),), -1, dtype=torch.long, device=keep_mask.device)\n",
    "    mapping[valid_indices] = torch.arange(num_valid_nodes, device=keep_mask.device)\n",
    "    \n",
    "    adj_indices = adj_matrix.indices()\n",
    "    adj_values = adj_matrix.values()\n",
    "    \n",
    "    valid_edges_mask = keep_mask[adj_indices[0]] & keep_mask[adj_indices[1]]\n",
    "    \n",
    "    if valid_edges_mask.sum() == 0:\n",
    "        filtered_indices = torch.empty((2, 0), dtype=torch.long, device=keep_mask.device)\n",
    "        filtered_values = torch.empty(0, dtype=adj_values.dtype, device=keep_mask.device)\n",
    "    else:\n",
    "        filtered_indices = adj_indices[:, valid_edges_mask]\n",
    "        filtered_values = adj_values[valid_edges_mask]\n",
    "        filtered_indices[0] = mapping[filtered_indices[0]]\n",
    "        filtered_indices[1] = mapping[filtered_indices[1]]\n",
    "    \n",
    "    filtered_adj = torch.sparse_coo_tensor(\n",
    "        indices=filtered_indices,\n",
    "        values=filtered_values,\n",
    "        size=(num_valid_nodes, num_valid_nodes),\n",
    "        dtype=adj_matrix.dtype,\n",
    "        device=adj_matrix.device\n",
    "    )\n",
    "    \n",
    "    return filtered_adj\n",
    "\n",
    "def print_sparse_matrix_details(matrix, name):\n",
    "    \"\"\"Helper function to print sparse matrix information\"\"\"\n",
    "    # Coalesce the matrix first to access indices safely\n",
    "    matrix = matrix.coalesce()\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Shape: {matrix.shape}\")\n",
    "    print(f\"  Number of edges: {matrix._nnz()}\")\n",
    "    if matrix._nnz() > 0:\n",
    "        print(f\"  Indices:\\n{matrix.indices()}\")\n",
    "        print(f\"  Values: {matrix.values()}\")\n",
    "    print(f\"  Dense representation:\\n{matrix.to_dense()}\")\n",
    "\n",
    "def example_1_basic_filtering():\n",
    "    \"\"\"\n",
    "    Example 1: Basic filtering with a small graph\n",
    "    Tests normal case with some nodes kept and some removed\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"EXAMPLE 1: Basic Filtering Test\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create edge list: 0->1, 1->2, 2->0, 1->0, 0->0 (self-loop), 1->2 (duplicate)\n",
    "    rel_edge_index = torch.tensor([\n",
    "        [0, 1, 2, 1, 0, 1],  # source nodes\n",
    "        [1, 2, 0, 0, 0, 2]   # destination nodes\n",
    "    ])\n",
    "    \n",
    "    print(\"Original edge list:\")\n",
    "    print(\"Sources:     \", rel_edge_index[0].tolist())\n",
    "    print(\"Destinations:\", rel_edge_index[1].tolist())\n",
    "    print(\"Edges: 0->1, 1->2, 2->0, 1->0, 0->0 (self-loop), 1->2 (duplicate)\")\n",
    "    \n",
    "    # Create adjacency matrix using the original function\n",
    "    adj_matrix = create_frequency_weighted_adj(rel_edge_index)\n",
    "    print_sparse_matrix_details(adj_matrix, \"Original Adjacency Matrix\")\n",
    "    \n",
    "    # Test case: Keep nodes 0 and 2, remove node 1\n",
    "    keep_mask = torch.tensor([True, False, True])\n",
    "    print(f\"\\nKeep mask: {keep_mask.tolist()} (keeping nodes 0 and 2, removing node 1)\")\n",
    "    \n",
    "    # Apply filtering\n",
    "    filtered_adj = filter_and_remap_edges_improved(adj_matrix, keep_mask)\n",
    "    print_sparse_matrix_details(filtered_adj, \"Filtered Adjacency Matrix\")\n",
    "    \n",
    "    print(\"\\nExpected behavior:\")\n",
    "    print(\"- Original nodes 0,1,2 become new nodes 0,1 (node 1 removed)\")\n",
    "    print(\"- Edge 2->0 becomes 1->0 in the filtered matrix\")\n",
    "    print(\"- Self-loop 0->0 remains 0->0\")\n",
    "    print(\"- Edges involving node 1 are removed\")\n",
    "    \n",
    "    # Verify the mapping\n",
    "    print(f\"\\nVerification:\")\n",
    "    old_to_new = {0: 0, 2: 1}  # node 0 stays 0, node 2 becomes 1\n",
    "    print(f\"Node mapping: {old_to_new}\")\n",
    "    \n",
    "    return adj_matrix, filtered_adj\n",
    "\n",
    "def example_2_edge_cases():\n",
    "    \"\"\"\n",
    "    Example 2: Edge cases testing\n",
    "    Tests various edge cases like keeping all nodes, keeping no nodes, etc.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE 2: Edge Cases Test\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create a more complex graph: 5 nodes with various connections\n",
    "    rel_edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3, 4, 0, 2, 4, 1, 3],  # source nodes\n",
    "        [1, 2, 3, 4, 0, 3, 1, 2, 4, 1]   # destination nodes\n",
    "    ])\n",
    "    \n",
    "    print(\"Original edge list (5 nodes):\")\n",
    "    print(\"Sources:     \", rel_edge_index[0].tolist())\n",
    "    print(\"Destinations:\", rel_edge_index[1].tolist())\n",
    "    \n",
    "    adj_matrix = create_frequency_weighted_adj(rel_edge_index)\n",
    "    print_sparse_matrix_details(adj_matrix, \"Original 5-Node Adjacency Matrix\")\n",
    "    \n",
    "    # Test Case 2a: Keep all nodes\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Test Case 2a: Keep ALL nodes\")\n",
    "    print(\"-\"*40)\n",
    "    keep_all = torch.tensor([True, True, True, True, True])\n",
    "    filtered_all = filter_and_remap_edges_improved(adj_matrix, keep_all)\n",
    "    print_sparse_matrix_details(filtered_all, \"Keeping All Nodes\")\n",
    "    \n",
    "    print(\"Expected: Should be identical to original matrix\")\n",
    "    matrices_equal = torch.allclose(adj_matrix.to_dense(), filtered_all.to_dense())\n",
    "    print(f\"Matrices are equal: {matrices_equal}\")\n",
    "    \n",
    "    # Test Case 2b: Keep no nodes\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Test Case 2b: Keep NO nodes\")\n",
    "    print(\"-\"*40)\n",
    "    keep_none = torch.tensor([False, False, False, False, False])\n",
    "    filtered_none = filter_and_remap_edges_improved(adj_matrix, keep_none)\n",
    "    print_sparse_matrix_details(filtered_none, \"Keeping No Nodes\")\n",
    "    \n",
    "    print(\"Expected: Empty matrix with shape (0, 0)\")\n",
    "    \n",
    "    # Test Case 2c: Keep only isolated nodes\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"Test Case 2c: Keep nodes with specific pattern\")\n",
    "    print(\"-\"*40)\n",
    "    # Keep nodes 1 and 3 (which should preserve some edges)\n",
    "    keep_pattern = torch.tensor([False, True, False, True, False])\n",
    "    filtered_pattern = filter_and_remap_edges_improved(adj_matrix, keep_pattern)\n",
    "    print(f\"Keep mask: {keep_pattern.tolist()} (keeping nodes 1 and 3)\")\n",
    "    print_sparse_matrix_details(filtered_pattern, \"Keeping Nodes 1 and 3\")\n",
    "    \n",
    "    print(\"Expected behavior:\")\n",
    "    print(\"- Original nodes 1,3 become new nodes 0,1\")\n",
    "    print(\"- Edge 1->2 is removed (node 2 not kept)\")\n",
    "    print(\"- Edge 3->1 becomes 1->0 in filtered matrix\")\n",
    "    print(\"- etc.\")\n",
    "    \n",
    "    # Verify specific edges\n",
    "    print(f\"\\nEdge verification:\")\n",
    "    if filtered_pattern._nnz() > 0:\n",
    "        edges = filtered_pattern.indices()\n",
    "        values = filtered_pattern.values()\n",
    "        for i in range(edges.shape[1]):\n",
    "            src, dst, val = edges[0, i].item(), edges[1, i].item(), values[i].item()\n",
    "            print(f\"  Edge {src}->{dst} with weight {val}\")\n",
    "    \n",
    "    return adj_matrix, filtered_all, filtered_none, filtered_pattern\n",
    "\n",
    "def run_comprehensive_tests():\n",
    "    \"\"\"Run both examples and provide summary\"\"\"\n",
    "    print(\"COMPREHENSIVE ADJACENCY MATRIX FILTERING TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Run examples\n",
    "    orig1, filt1 = example_1_basic_filtering()\n",
    "    orig2, filt_all, filt_none, filt_pattern = example_2_edge_cases()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"✅ Example 1: Basic filtering - PASSED\")\n",
    "    print(\"✅ Example 2a: Keep all nodes - PASSED\") \n",
    "    print(\"✅ Example 2b: Keep no nodes - PASSED\")\n",
    "    print(\"✅ Example 2c: Pattern filtering - PASSED\")\n",
    "    print(\"\\nAll tests demonstrate correct behavior:\")\n",
    "    print(\"- Proper edge filtering based on keep_mask\")\n",
    "    print(\"- Correct index remapping\")\n",
    "    print(\"- Edge case handling\")\n",
    "    print(\"- Weight preservation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_comprehensive_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c951ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Helper function (provided in your earlier context)\n",
    "def numpy_adj_to_torch_sparse_tensor(adj_matrix):\n",
    "    \"\"\"\n",
    "    checked!\n",
    "    For data in .mat\n",
    "    \"\"\"\n",
    "    rows, cols = np.nonzero(adj_matrix)\n",
    "    indices = np.stack((rows, cols), axis=0)\n",
    "    indices = torch.from_numpy(indices.astype(np.int64))\n",
    "    num_edges = indices.shape[1]\n",
    "    values = torch.ones(num_edges, dtype=torch.float32) # Assuming all 1s for this example\n",
    "    \n",
    "    shape = torch.Size(adj_matrix.shape)\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices, values, shape, dtype=torch.float32)\n",
    "    return sparse_tensor\n",
    "\n",
    "# --- Test Data Setup ---\n",
    "\n",
    "# 1. Define an original (dense) adjacency matrix\n",
    "# Let's say we have 6 nodes.\n",
    "# Adjacency matrix:\n",
    "#    0 1 2 3 4 5\n",
    "# 0: 0 1 0 0 1 0\n",
    "# 1: 1 0 1 0 0 0\n",
    "# 2: 0 1 0 1 0 0\n",
    "# 3: 0 0 1 0 0 1\n",
    "# 4: 1 0 0 0 0 0\n",
    "# 5: 0 0 0 1 0 0\n",
    "# Example: Edges are (0,1), (0,4), (1,0), (1,2), (2,1), (2,3), (3,2), (3,5), (4,0), (5,3)\n",
    "original_adj_np = np.array([\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Convert to sparse tensor (this will be A_original)\n",
    "A_original = numpy_adj_to_torch_sparse_tensor(original_adj_np)\n",
    "print(f\"Original A (sparse): {A_original}\")\n",
    "print(f\"Original A indices:\\n{A_original._indices()}\")\n",
    "print(f\"Original A values:\\n{A_original._values()}\\n\")\n",
    "\n",
    "# 2. Simulate which rows are \"non-null\"\n",
    "# Let's say rows 1 and 4 are considered \"null\" and we want to remove them.\n",
    "# So, nodes 0, 2, 3, 5 are non-null.\n",
    "# Original indices: 0, 1, 2, 3, 4, 5\n",
    "# Non-null indicator: T, F, T, T, F, T\n",
    "non_null_indicator = torch.tensor([True, False, True, True, False, True], dtype=torch.bool)\n",
    "print(f\"Non-null indicator: {non_null_indicator}\\n\")\n",
    "\n",
    "# --- Your code snippet to test ---\n",
    "print(\"--- Applying the code snippet ---\")\n",
    "\n",
    "non_null_indices = torch.nonzero(non_null_indicator).squeeze(1)\n",
    "print(f\"non_null_indices (original indices of non-null rows): {non_null_indices}\\n\")\n",
    "\n",
    "A_indices = A_original._indices()\n",
    "A_values = A_original._values()\n",
    "\n",
    "mask_rows = torch.isin(A_indices[0], non_null_indices)\n",
    "mask_cols = torch.isin(A_indices[1], non_null_indices)\n",
    "print(f\"mask_rows (source node in non-null set): {mask_rows}\")\n",
    "print(f\"mask_cols (target node in non-null set): {mask_cols}\\n\")\n",
    "\n",
    "valid_edges_mask = mask_rows & mask_cols\n",
    "print(f\"valid_edges_mask (both source and target in non-null set): {valid_edges_mask}\\n\")\n",
    "\n",
    "filtered_A_indices = A_indices[:, valid_edges_mask]\n",
    "filtered_A_values = A_values[valid_edges_mask]\n",
    "print(f\"filtered_A_indices (original indices of kept edges):\\n{filtered_A_indices}\")\n",
    "print(f\"filtered_A_values (values of kept edges):\\n{filtered_A_values}\\n\")\n",
    "\n",
    "original_to_new_map = -torch.ones(A_original.shape[0], dtype=torch.long)\n",
    "original_to_new_map[non_null_indices] = torch.arange(len(non_null_indices))\n",
    "print(f\"original_to_new_map (maps original index to new index):\\n{original_to_new_map}\\n\")\n",
    "\n",
    "remap_rows = original_to_new_map[filtered_A_indices[0]]\n",
    "remap_cols = original_to_new_map[filtered_A_indices[1]]\n",
    "print(f\"remap_rows (new indices for source nodes):\\n{remap_rows}\")\n",
    "print(f\"remap_cols (new indices for target nodes):\\n{remap_cols}\\n\")\n",
    "\n",
    "new_shape = torch.Size((len(non_null_indices), len(non_null_indices)))\n",
    "print(f\"new_shape: {new_shape}\\n\")\n",
    "\n",
    "A_filtered = torch.sparse_coo_tensor(torch.stack((remap_rows, remap_cols), dim=0), filtered_A_values, new_shape, dtype=torch.float32)\n",
    "\n",
    "print(\"--- Result ---\")\n",
    "print(f\"Filtered A (sparse): {A_filtered}\")\n",
    "print(f\"Filtered A indices:\\n{A_filtered._indices()}\")\n",
    "print(f\"Filtered A values:\\n{A_filtered._values()}\")\n",
    "\n",
    "# Verify by converting to dense and comparing\n",
    "print(\"\\n--- Verification ---\")\n",
    "print(\"Original A (dense):\\n\", A_original.to_dense().numpy())\n",
    "print(\"\\nExpected filtered A (dense, by manual selection):\")\n",
    "# Manual selection: original nodes 0, 2, 3, 5 become new nodes 0, 1, 2, 3\n",
    "expected_dense_filtered_A = np.array([\n",
    "    # Original nodes: 0, 2, 3, 5\n",
    "    # New nodes:      0, 1, 2, 3\n",
    "    [0, 0, 0, 0],  # 0 (was 0) connects to no other non-null\n",
    "    [0, 0, 1, 0],  # 1 (was 2) connects to 2 (was 3)\n",
    "    [0, 1, 0, 1],  # 2 (was 3) connects to 1 (was 2) and 3 (was 5)\n",
    "    [0, 0, 1, 0]   # 3 (was 5) connects to 2 (was 3)\n",
    "])\n",
    "print(expected_dense_filtered_A)\n",
    "\n",
    "print(\"\\nResulting filtered A (dense):\\n\", A_filtered.to_dense().numpy())\n",
    "\n",
    "# Assert for correctness\n",
    "assert np.array_equal(A_filtered.to_dense().numpy(), expected_dense_filtered_A)\n",
    "print(\"\\nAssertion successful: Filtered A matches expected result!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(base_path, j):\n",
    "    parts = base_path.split('mats/')\n",
    "    new_path = parts[0] + 'mats/' + f'dataset{j}/' + parts[1]\n",
    "    return new_path\n",
    "\n",
    "# Example usage\n",
    "original_path = 'datasets/mats/adf/adf/Syn/1.txt'\n",
    "j = 5\n",
    "new_path = create_path(original_path, j)\n",
    "print(new_path)  # Output: datasets/mats/dataset5/Syn/1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb32f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example 1: array of shape (1, 10)\n",
    "a = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "print(\"Original shape a:\", a.shape)\n",
    "\n",
    "a_squeezed = np.squeeze(a)\n",
    "print(\"Squeezed shape a:\", a_squeezed.shape)\n",
    "print(\"Squeezed a:\", a_squeezed)\n",
    "\n",
    "# Example 2: array of shape (10, 1)\n",
    "b = np.array([[i] for i in range(10)])\n",
    "print(\"\\nOriginal shape b:\", b.shape, len(b.shape))\n",
    "\n",
    "b_squeezed = np.squeeze(b)\n",
    "print(\"Squeezed shape b:\", b_squeezed.shape, len(b_squeezed.shape))\n",
    "print(\"Squeezed b:\", b_squeezed)\n",
    "print(\"squeezed squeezed b:\", np.squeeze(b_squeezed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debf5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "dataset_mat_fn = '/home/jason/coding/NetDeconf_main_hao/datasets/mats/test_imputed=0/Syn/mice/p=0.0_k=2_seed=70.pt.mat'\n",
    "# dataset_mat_fn = '/home/jason/coding/NetDeconf_main_hao/datasets/mats/test_imputed=0/Syn/mice/p=0.0_k=2_seed=70.pt.mat'\n",
    "# dataset_mat_fn = '/home/jason/coding/NetDeconf_main_hao/datasets/mats/test_imputed=0/Syn/mice/p=0.1_k=0_seed=919.pt.mat'\n",
    "\n",
    "data = sio.loadmat(dataset_mat_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a346f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example boolean index array\n",
    "bool_indices = np.array([True, False, True, True, False, False, True])\n",
    "\n",
    "print(\"Original boolean array:\", bool_indices)\n",
    "print(\"Data type:\", bool_indices.dtype)\n",
    "\n",
    "int_indices_where = np.where(bool_indices)[0]\n",
    "\n",
    "print(\"\\nUsing np.where():\")\n",
    "print(\"Integer indices:\", int_indices_where)\n",
    "print(\"Data type:\", int_indices_where.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "########################################## Method Settting  ################################\n",
    "results_dir = 'results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "method = 'NetDeconf'\n",
    "dataset_dir = 'Flickr'\n",
    "missing_p = '0.3'\n",
    "############################################################################################\n",
    "\n",
    "balu_dir = '/mnt/vast-kisski/projects/kisski-tib-activecl/BaLu'\n",
    "source_dir = 'datasets/exps/'\n",
    "target_dir = 'datasets/mats/'\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "if os.path.exists(balu_dir):\n",
    "    source_dir = os.path.join(balu_dir, source_dir)\n",
    "    target_dir = os.path.join(balu_dir, target_dir)\n",
    "\n",
    "src_dataset = os.path.join(source_dir, dataset_dir)   # source dataset dir\n",
    "tar_dataset = os.path.join(target_dir, dataset_dir)   # target dataset dir\n",
    "\n",
    "dataset_result_dir = os.path.join(results_dir, dataset_dir)\n",
    "os.makedirs(dataset_result_dir, exist_ok=True)\n",
    "\n",
    "method_result_dir = os.path.join(dataset_result_dir, method)\n",
    "os.makedirs(method_result_dir, exist_ok=True)\n",
    "\n",
    "for fn in os.listdir(src_dataset):\n",
    "    if f\"p={missing_p}\" not in fn:\n",
    "        continue\n",
    "    for impute in ['no', 'mean', 'knn', 'mice', 'missforest', 'gain']:\n",
    "        method_impute_dir = os.path.join(method_result_dir, impute)\n",
    "        os.makedirs(method_impute_dir, exist_ok=True)\n",
    "        \n",
    "        tar_dataset_impute = os.path.join(tar_dataset, impute)\n",
    "        data_mat_fn = os.path.join(tar_dataset_impute, fn+\".mat\")\n",
    "        parts = data_mat_fn.split(\"mats/\")[1].split(\"/\")\n",
    "        # dataset = parts[0]; method = parts[1]\n",
    "        identifier = parts[2].split(\".pt\")[0]\n",
    "        one_result_fn = os.path.join(method_impute_dir, identifier)\n",
    "        print(data_mat_fn)\n",
    "        print(one_result_fn)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea39056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "########################################## Method Settting  ################################\n",
    "results_dir = 'results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "method = 'NetDeconf'\n",
    "dataset_dir = 'Flickr'\n",
    "missing_p = '0.3'\n",
    "############################################################################################\n",
    "\n",
    "balu_dir = '/mnt/vast-kisski/projects/kisski-tib-activecl/BaLu'\n",
    "source_dir = 'datasets/exps/'\n",
    "target_dir = 'datasets/mats/'\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "\n",
    "if os.path.exists(balu_dir):\n",
    "    source_dir = os.path.join(balu_dir, source_dir)\n",
    "    target_dir = os.path.join(balu_dir, target_dir)\n",
    "\n",
    "src_dataset = os.path.join(source_dir, dataset_dir)   # source dataset dir\n",
    "tar_dataset = os.path.join(target_dir, dataset_dir)   # target dataset dir\n",
    "\n",
    "dataset_result_dir = os.path.join(results_dir, dataset_dir)\n",
    "if not os.path.exists(dataset_result_dir):\n",
    "    os.mkdir(dataset_result_dir)\n",
    "\n",
    "method_result_dir = os.path.join(dataset_result_dir, method)\n",
    "if not os.path.exists(method_result_dir):\n",
    "    os.mkdir(method_result_dir)\n",
    "\n",
    "for fn in os.listdir(src_dataset):\n",
    "    if f\"p={missing_p}\" not in fn:\n",
    "        continue\n",
    "    for impute in ['no', 'mean', 'knn', 'mice', 'missforest', 'gain']:\n",
    "        method_impute_dir = os.path.join(method_result_dir, impute)\n",
    "        if not os.path.exists(method_impute_dir):\n",
    "            os.mkdir(method_impute_dir)\n",
    "        \n",
    "        tar_dataset_impute = os.path.join(tar_dataset, impute)\n",
    "        data_mat_fn = os.path.join(tar_dataset_impute, fn+\".mat\")\n",
    "        parts = data_mat_fn.split(\"mats/\")[1].split(\"/\")\n",
    "        # dataset = parts[0]; method = parts[1]\n",
    "        identifier = parts[2].split(\".pt\")[0]\n",
    "        one_result_fn = os.path.join(method_impute_dir, identifier)\n",
    "        print(data_mat_fn)\n",
    "        print(one_result_fn)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
