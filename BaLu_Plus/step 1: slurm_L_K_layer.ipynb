{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47725ef5",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adcc7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch A100_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cluster_map = {\"A100\":\"\"\"#SBATCH -p kisski\n",
    "#SBATCH -G A100:1                    \n",
    "#SBATCH --mem=20G\"\"\",\n",
    "\"H100\": \"\"\"#SBATCH -p kisski-h100\n",
    "#SBATCH -G H100:1                    \n",
    "#SBATCH --mem=20G\"\"\",\n",
    "\"CPU\": \"\"\"#SBATCH --partition=jupyter:cpu\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=40G\"\"\"}\n",
    "\n",
    "format = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=BaLu_GNN_{dataset}_{imputer}\n",
    "{cluster}\n",
    "#SBATCH --time=12:00:00\n",
    "#SBATCH --output=run_%x_%j.out\n",
    "#SBATCH --error=run_%x_%j.err\n",
    "#SBATCH --mail-type=FAIL # Email on start, end, failure\n",
    "#SBATCH --mail-user=hao.huang@tib.eu # <-- Replace with your real email\n",
    "echo \"===== JOB STARTED =====\"\n",
    "echo \"Hostname: $(hostname)\"\n",
    "echo \"Date: $(date)\"\n",
    "echo \"User: $USER\"\n",
    "# Load environment\n",
    "module load miniforge3\n",
    "module load gcc/13.2.0\n",
    "module load cuda/11.8\n",
    "# module load gcc/13.2.0\n",
    "# module load cuda/12.6.2\n",
    "# Set up conda\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\"\n",
    "conda activate /mnt/vast-kisski/projects/kisski-tib-activecl/cenv\n",
    "# Diagnostics\n",
    "echo \"Which python: $(which python)\"\n",
    "python -c \"import torch; print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\"\n",
    "# Navigate to project directory\n",
    "cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\n",
    "echo \"--- Running: run_exps.py ---\"\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.0  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.1  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.3  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "\n",
    "echo \"===== JOB COMPLETED =====\"\n",
    "echo \"Date: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "datasets_org = ['Syn_M=None_SimRel=1_Rel=4', 'Youtube_M=20_SimRel=1_Rel=4', 'BlogCatalog1_M=20_SimRel=0_Rel=1', 'Flickr1_M=20_SimRel=0_Rel=1']      # network relationships not based on similarity\n",
    "datasets = [e+\"_MCAR\" for e in datasets_org]\n",
    "\n",
    "imputers = ['BaLu_GRAPE', 'BaLu_IGMC', 'GRAPE', 'IGMC']\n",
    "Layers = [(\"64 64 64\", \"64 64\"), (\"64 64\", \"64 64\"), (\"64 64\", \"64\"), (\"64 64 64\", \"64\")]\n",
    "GNNs = ['GCN', 'GAT', 'GraphSAGE', 'RGCN']\n",
    "rel_dropouts = [0.0, 0.1, 0.2, 0.3]\n",
    "betas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "gammas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "etas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "default_paras = {'imputer': imputers[0],\n",
    "                 'dataset': datasets[0], \n",
    "                'rel_dropout': rel_dropouts[0],\n",
    "                'beta': betas[1],\n",
    "                'gamma': gammas[1],\n",
    "                'eta': etas[1]}\n",
    "\n",
    "missing_ps = [0.0, 0.1, 0.3]\n",
    "print(\"cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\")\n",
    "\n",
    "\n",
    "################################################################################################################################################\n",
    "cluster = 'A100'        # H100, CPU\n",
    "slurm_dir = f'{cluster}_step1_L_K_Layer'\n",
    "################################################################################################################################################\n",
    "\n",
    "os.makedirs(slurm_dir, exist_ok=True)\n",
    "\n",
    "def file_name(paras: dict):\n",
    "    s = \"\"\n",
    "    for k, v in paras.items():\n",
    "        s += f\"_{k}={v}\"\n",
    "    return s\n",
    "\n",
    "for dataset in datasets:\n",
    "    for imputer in imputers[:2]:    # only for 'BaLu_GRAPE', 'BaLu_IGMC'\n",
    "        for layers in Layers:\n",
    "            L_node_dim = layers[0]\n",
    "            K_node_dim = layers[1]\n",
    "\n",
    "            slurm_content = format.format(cluster=cluster_map[cluster], dataset=dataset, \n",
    "                                          imputer=imputer, L_node_dim=L_node_dim, K_node_dim=K_node_dim)\n",
    "\n",
    "            L_node_dim_1 = L_node_dim.replace(\" \", \"-\")\n",
    "            K_node_dim_1 = K_node_dim.replace(\" \", \"-\")\n",
    "            filename = os.path.join(slurm_dir, f\"{dataset}_imputer={imputer}_L={L_node_dim_1}_K={K_node_dim_1}.slurm\")\n",
    "\n",
    "            with open(filename, \"w\") as f:\n",
    "                f.write(slurm_content)\n",
    "            sbatch_command = f\"sbatch {filename}\"\n",
    "            print(sbatch_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c178732",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Flickr1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/BlogCatalog1_M=20_SimRel=0_Rel=1_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Youtube_M=20_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_GRAPE_L=64-64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64-64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64_K=64.slurm\n",
      "sbatch CPU_step1_L_K_Layer/Syn_M=None_SimRel=1_Rel=4_MCAR_imputer=BaLu_IGMC_L=64-64-64_K=64.slurm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cluster_map = {\"A100\":\"\"\"#SBATCH -p kisski\n",
    "#SBATCH -G A100:1                    \n",
    "#SBATCH --mem=20G\"\"\",\n",
    "\"H100\": \"\"\"#SBATCH -p kisski-h100\n",
    "#SBATCH -G H100:1                    \n",
    "#SBATCH --mem=20G\"\"\",\n",
    "\"CPU\": \"\"\"#SBATCH --partition=jupyter:cpu\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=40G\"\"\"}\n",
    "\n",
    "format = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name=BaLu_GNN_{dataset}_{imputer}\n",
    "{cluster}\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --output=run_%x_%j.out\n",
    "#SBATCH --error=run_%x_%j.err\n",
    "#SBATCH --mail-type=FAIL # Email on start, end, failure\n",
    "#SBATCH --mail-user=hao.huang@tib.eu # <-- Replace with your real email\n",
    "echo \"===== JOB STARTED =====\"\n",
    "echo \"Hostname: $(hostname)\"\n",
    "echo \"Date: $(date)\"\n",
    "echo \"User: $USER\"\n",
    "# Load environment\n",
    "module load miniforge3\n",
    "module load gcc/13.2.0\n",
    "module load cuda/11.8\n",
    "# module load gcc/13.2.0\n",
    "# module load cuda/12.6.2\n",
    "# Set up conda\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\"\n",
    "conda activate /mnt/vast-kisski/projects/kisski-tib-activecl/cenv\n",
    "# Diagnostics\n",
    "echo \"Which python: $(which python)\"\n",
    "python -c \"import torch; print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\"\n",
    "# Navigate to project directory\n",
    "cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\n",
    "echo \"--- Running: run_exps.py ---\"\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.0  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.1  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "python3 -u run_exps.py --model_name BaLu_Plus --imputer {imputer} --dataset {dataset} --missing_p 0.3  --gconv GCN --rconv GCN --imputer_node_dims {L_node_dim} --interference_node_dims {K_node_dim}\n",
    "\n",
    "echo \"===== JOB COMPLETED =====\"\n",
    "echo \"Date: $(date)\"\n",
    "\"\"\"\n",
    "\n",
    "datasets_org = ['Syn_M=None_SimRel=1_Rel=4', 'Youtube_M=20_SimRel=1_Rel=4', 'BlogCatalog1_M=20_SimRel=0_Rel=1', 'Flickr1_M=20_SimRel=0_Rel=1']      # network relationships not based on similarity\n",
    "datasets = [e+\"_MCAR\" for e in datasets_org]\n",
    "\n",
    "imputers = ['BaLu_GRAPE', 'BaLu_IGMC', 'GRAPE', 'IGMC']\n",
    "Layers = [(\"64 64 64\", \"64 64\"), (\"64 64\", \"64 64\"), (\"64 64\", \"64\"), (\"64 64 64\", \"64\")]\n",
    "GNNs = ['GCN', 'GAT', 'GraphSAGE', 'RGCN']\n",
    "rel_dropouts = [0.0, 0.1, 0.2, 0.3]\n",
    "betas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "gammas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "etas = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "default_paras = {'imputer': imputers[0],\n",
    "                 'dataset': datasets[0], \n",
    "                'rel_dropout': rel_dropouts[0],\n",
    "                'beta': betas[1],\n",
    "                'gamma': gammas[1],\n",
    "                'eta': etas[1]}\n",
    "\n",
    "missing_ps = [0.0, 0.1, 0.3]\n",
    "print(\"cd /mnt/vast-kisski/projects/kisski-tib-activecl/BaLu_Plus/\")\n",
    "\n",
    "\n",
    "################################################################################################################################################\n",
    "cluster = 'CPU'        # H100, CPU\n",
    "slurm_dir = f'{cluster}_step1_L_K_Layer'\n",
    "################################################################################################################################################\n",
    "\n",
    "os.makedirs(slurm_dir, exist_ok=True)\n",
    "\n",
    "def file_name(paras: dict):\n",
    "    s = \"\"\n",
    "    for k, v in paras.items():\n",
    "        s += f\"_{k}={v}\"\n",
    "    return s\n",
    "\n",
    "for dataset in datasets[::-1]:\n",
    "    for imputer in imputers[:2]:    # only for 'BaLu_GRAPE', 'BaLu_IGMC'\n",
    "        for layers in Layers:\n",
    "            L_node_dim = layers[0]\n",
    "            K_node_dim = layers[1]\n",
    "\n",
    "            slurm_content = format.format(cluster=cluster_map[cluster], dataset=dataset, \n",
    "                                          imputer=imputer, L_node_dim=L_node_dim, K_node_dim=K_node_dim)\n",
    "\n",
    "            L_node_dim_1 = L_node_dim.replace(\" \", \"-\")\n",
    "            K_node_dim_1 = K_node_dim.replace(\" \", \"-\")\n",
    "            filename = os.path.join(slurm_dir, f\"{dataset}_imputer={imputer}_L={L_node_dim_1}_K={K_node_dim_1}.slurm\")\n",
    "\n",
    "            with open(filename, \"w\") as f:\n",
    "                f.write(slurm_content)\n",
    "            sbatch_command = f\"sbatch {filename}\"\n",
    "            print(sbatch_command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
