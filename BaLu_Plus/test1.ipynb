{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(n_attrs=20, n_rel_types=1, node_feature_dim=20, edge_attr_dim=1, n_units=1039, x=[1059, 20], is_unit=[1059], treatment=[1039], outcome=[1039], true_effect=[1039], treatment_mask=[1039], outcome_mask=[1039], train_mask=[1039], val_mask=[1039], test_mask=[1039], observed_mask=[20780], edge_index=[2, 41560], edge_attr=[41560], rel_edge_index=[2, 13524], rel_edge_type=[13524], arr_X=[1039, 20], arr_YF=[1039], arr_Y1=[1039], arr_Y0=[1039], arr_Adj=[1, 1039, 1039])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def filter_and_remap_edges(edge_index, unit_mask, n_units, n_attrs):\n",
    "    \"\"\"\n",
    "    Filter and remap edges in bipartite graph (units <-> attributes).\n",
    "    \n",
    "    Args:\n",
    "        edge_index: torch.Tensor of shape [2, E] \n",
    "        unit_mask: torch.Tensor of shape [n_units] with boolean values for units to keep\n",
    "        n_units: Original number of units\n",
    "        n_attrs: Number of attributes (unchanged)\n",
    "    \n",
    "    Returns:\n",
    "        new_edge_index: torch.Tensor with filtered and remapped edges\n",
    "    \"\"\"\n",
    "    # Create mapping for unit nodes (0 to n_units-1)\n",
    "    unit_mapping = torch.cumsum(unit_mask, dim=0) - 1\n",
    "    unit_mapping[~unit_mask] = -1\n",
    "    \n",
    "    # Create mapping for attribute nodes (n_units to n_units+n_attrs-1)\n",
    "    # Attribute indices need to be shifted down by the number of removed units\n",
    "    n_units_kept = unit_mask.sum().item()\n",
    "    attr_mapping = torch.arange(n_attrs) + n_units_kept  # New attribute indices\n",
    "    \n",
    "    # Create full node mapping\n",
    "    full_mapping = torch.full((n_units + n_attrs,), -1, dtype=torch.long)\n",
    "    full_mapping[:n_units] = unit_mapping\n",
    "    full_mapping[n_units:] = attr_mapping\n",
    "    \n",
    "    # Filter edges: keep only edges involving kept units\n",
    "    unit_nodes_in_edges = edge_index[0] < n_units  # Source is unit\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units  # Source is attribute\n",
    "    \n",
    "    # For unit->attr edges: keep if unit is in mask\n",
    "    unit_to_attr = unit_nodes_in_edges & unit_mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    # For attr->unit edges: keep if target unit is in mask  \n",
    "    attr_to_unit = attr_nodes_in_edges & unit_mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    \n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    \n",
    "    # Apply mapping to filtered edges\n",
    "    filtered_edges = edge_index[:, edge_mask]\n",
    "    new_edge_index = full_mapping[filtered_edges]\n",
    "    \n",
    "    return new_edge_index\n",
    "\n",
    "\n",
    "def filter_dataset(data: Data, mask: torch.Tensor) -> Data:\n",
    "    \"\"\"\n",
    "    Filter dataset to keep only units where mask[i] = True.\n",
    "    Keeps ALL attribute nodes but updates their indices.\n",
    "    \n",
    "    Args:\n",
    "        data: PyTorch Geometric Data object with bipartite structure\n",
    "        mask: Boolean tensor of shape [n_units] for units to keep\n",
    "    \n",
    "    Returns:\n",
    "        train_data: New Data object with filtered units and remapped structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure mask is boolean and on CPU for numpy operations\n",
    "    mask = mask.bool()\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    n_units_kept = mask.sum().item()\n",
    "    \n",
    "    # Create new data object\n",
    "    train_data = copy.deepcopy(data)\n",
    "    \n",
    "    # Copy metadata (n_attrs doesn't change)\n",
    "    for attr in ['n_attrs', 'n_rel_types', 'node_feature_dim', 'edge_attr_dim']:\n",
    "        if hasattr(data, attr):\n",
    "            setattr(train_data, attr, getattr(data, attr))\n",
    "    \n",
    "    # Update n_units to filtered count\n",
    "    # n_units, n_attrs = data.n_units, data.n_attrs\n",
    "    train_data.n_units = n_units_kept\n",
    "\n",
    "    \n",
    "    # 1. Filter node features: keep filtered units + all attributes\n",
    "    if hasattr(data, 'x') and data.x is not None:\n",
    "        unit_features = data.x[:data.n_units][mask]  # Filter unit nodes\n",
    "        attr_features = data.x[data.n_units:]        # Keep all attribute nodes\n",
    "        train_data.x = torch.cat([unit_features, attr_features], dim=0)\n",
    "    \n",
    "    # 2. Filter is_unit: keep filtered units + all attributes  \n",
    "    if hasattr(data, 'is_unit') and data.is_unit is not None:\n",
    "        unit_is_unit = data.is_unit[:data.n_units][mask]  # Filter unit flags\n",
    "        attr_is_unit = data.is_unit[data.n_units:]        # Keep attribute flags\n",
    "        train_data.is_unit = torch.cat([unit_is_unit, attr_is_unit], dim=0)\n",
    "    \n",
    "    # 3. Filter unit-level tensors\n",
    "    if hasattr(data, 'treatment') and data.treatment is not None:\n",
    "        train_data.treatment = data.treatment[mask]\n",
    "    \n",
    "    if hasattr(data, 'outcome') and data.outcome is not None:\n",
    "        train_data.outcome = data.outcome[mask]\n",
    "    \n",
    "    if hasattr(data, 'true_effect') and data.true_effect is not None:\n",
    "        train_data.true_effect = data.true_effect[mask]\n",
    "    \n",
    "    # 4. Filter unit-level masks\n",
    "    if hasattr(data, 'treatment_mask') and data.treatment_mask is not None:\n",
    "        train_data.treatment_mask = data.treatment_mask[mask]\n",
    "    \n",
    "    if hasattr(data, 'outcome_mask') and data.outcome_mask is not None:\n",
    "        train_data.outcome_mask = data.outcome_mask[mask]\n",
    "    \n",
    "    # 5. Filter split masks (train/val/test)\n",
    "    if hasattr(data, 'train_mask') and data.train_mask is not None:\n",
    "        train_data.train_mask = data.train_mask[mask]\n",
    "    \n",
    "    if hasattr(data, 'val_mask') and data.val_mask is not None:\n",
    "        train_data.val_mask = data.val_mask[mask]\n",
    "    \n",
    "    if hasattr(data, 'test_mask') and data.test_mask is not None:\n",
    "        train_data.test_mask = data.test_mask[mask]\n",
    "    \n",
    "    # 6. Filter observed_mask (reshape, filter, flatten)\n",
    "    if hasattr(data, 'observed_mask') and data.observed_mask is not None:\n",
    "        # Reshape to [n_units, n_attrs], filter units, then flatten\n",
    "        observed_reshaped = data.observed_mask.view(data.n_units, data.n_attrs)\n",
    "        observed_filtered = observed_reshaped[mask]  # Shape: [n_units_kept, n_attrs]\n",
    "        train_data.observed_mask = observed_filtered.flatten()\n",
    "    \n",
    "    # 7. Filter and remap bipartite edges (unit <-> attribute)\n",
    "    if hasattr(data, 'edge_index') and data.edge_index is not None:\n",
    "        train_data.edge_index = filter_and_remap_edges(\n",
    "            data.edge_index, mask, data.n_units, data.n_attrs\n",
    "        )\n",
    "        \n",
    "        # Filter edge attributes based on which edges were kept\n",
    "        if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n",
    "            # Need to determine which edges were kept\n",
    "            unit_nodes_in_edges = data.edge_index[0] < data.n_units\n",
    "            attr_nodes_in_edges = data.edge_index[0] >= data.n_units\n",
    "            \n",
    "            unit_to_attr = unit_nodes_in_edges & mask[data.edge_index[0].clamp(max=data.n_units-1)]\n",
    "            attr_to_unit = attr_nodes_in_edges & mask[data.edge_index[1].clamp(max=data.n_units-1)]\n",
    "            \n",
    "            edge_mask = unit_to_attr | attr_to_unit\n",
    "            train_data.edge_attr = data.edge_attr[edge_mask]\n",
    "    \n",
    "    # 8. Filter relational edges (unit <-> unit only)\n",
    "    if hasattr(data, 'rel_edge_index') and data.rel_edge_index is not None:\n",
    "        # Relational edges only involve units (indices 0 to n_units-1)\n",
    "        rel_edge_mask = mask[data.rel_edge_index[0]] & mask[data.rel_edge_index[1]]\n",
    "        filtered_rel_edges = data.rel_edge_index[:, rel_edge_mask]\n",
    "        \n",
    "        # Remap unit indices (0 to n_units_kept-1)\n",
    "        unit_mapping = torch.cumsum(mask, dim=0) - 1\n",
    "        train_data.rel_edge_index = unit_mapping[filtered_rel_edges]\n",
    "        \n",
    "        # Filter relational edge types\n",
    "        if hasattr(data, 'rel_edge_type') and data.rel_edge_type is not None:\n",
    "            train_data.rel_edge_type = data.rel_edge_type[rel_edge_mask]\n",
    "    \n",
    "    # 9. Filter adjacency matrix (for network baselines)\n",
    "    # if hasattr(data, 'A') and data.A is not None:\n",
    "    #     # Handle sparse tensor - only involves units\n",
    "    #     if hasattr(data.A, 'to_dense'):\n",
    "    #         adj_dense = data.A.to_dense().cpu().numpy()\n",
    "    #     else:\n",
    "    #         adj_dense = data.A.cpu().numpy()\n",
    "        \n",
    "    #     # Filter adjacency matrix (units only)\n",
    "    #     filtered_adj = adj_dense[np.ix_(mask_np, mask_np)]\n",
    "        \n",
    "    #     # Convert back to same format as original\n",
    "    #     if hasattr(data.A, 'to_dense'):\n",
    "    #         indices = torch.nonzero(torch.tensor(filtered_adj)).t()\n",
    "    #         values = torch.tensor(filtered_adj)[torch.nonzero(torch.tensor(filtered_adj), as_tuple=True)]\n",
    "    #         train_data.A = torch.sparse_coo_tensor(\n",
    "    #             indices=indices,\n",
    "    #             values=values,\n",
    "    #             size=filtered_adj.shape\n",
    "    #         ).to(data.A.device)\n",
    "    #     else:\n",
    "    #         train_data.A = torch.tensor(filtered_adj, device=data.A.device, dtype=data.A.dtype)\n",
    "    \n",
    "    # 10. Filter tabular data (numpy arrays) - units only\n",
    "    if hasattr(data, 'arr_X') and data.arr_X is not None:\n",
    "        train_data.arr_X = data.arr_X[mask_np]\n",
    "    \n",
    "    if hasattr(data, 'arr_YF') and data.arr_YF is not None:\n",
    "        train_data.arr_YF = data.arr_YF[mask_np]\n",
    "    \n",
    "    if hasattr(data, 'arr_Y1') and data.arr_Y1 is not None:\n",
    "        train_data.arr_Y1 = data.arr_Y1[mask_np]\n",
    "    \n",
    "    if hasattr(data, 'arr_Y0') and data.arr_Y0 is not None:\n",
    "        train_data.arr_Y0 = data.arr_Y0[mask_np]\n",
    "    \n",
    "    # Filter multi-dimensional adjacency matrix (units only)\n",
    "    if hasattr(data, 'arr_Adj') and data.arr_Adj is not None:\n",
    "        if len(data.arr_Adj.shape) == 2:  # Single adjacency matrix\n",
    "            train_data.arr_Adj = data.arr_Adj[np.ix_(mask_np, mask_np)]\n",
    "        elif len(data.arr_Adj.shape) == 3:  # Multi-relational adjacency matrices\n",
    "            # Convert boolean mask to indices first:\n",
    "            node_indices = np.where(mask_np)[0]\n",
    "            # For 3D arrays [R, N, N], filter the last two dimensions:\n",
    "            train_data.arr_Adj = data.arr_Adj[:, node_indices, :][:, :, node_indices]\n",
    "            # train_data.arr_Adj = data.arr_Adj[:, np.ix_(mask_np, mask_np)]\n",
    "    \n",
    "    # # 11. Filter dataframes (units only)\n",
    "    # if hasattr(data, 'df_full') and data.df_full is not None:\n",
    "    #     train_data.df_full = data.df_full[mask_np].reset_index(drop=True)\n",
    "    \n",
    "    # if hasattr(data, 'df_miss') and data.df_miss is not None:\n",
    "    #     train_data.df_miss = data.df_miss[mask_np].reset_index(drop=True)\n",
    "    \n",
    "    # if hasattr(data, 'df_imputed') and data.df_imputed is not None:\n",
    "    #     train_data.df_imputed = data.df_imputed[mask_np].reset_index(drop=True)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Convenience functions\n",
    "def create_train_val_data(data: Data) -> Data:\n",
    "    \"\"\"Create dataset with only train and validation units.\"\"\"\n",
    "    mask = data.train_mask | data.val_mask\n",
    "    return filter_dataset(data, mask)\n",
    "\n",
    "\n",
    "def create_train_data_only(data: Data) -> Data:\n",
    "    \"\"\"Create dataset with only training units.\"\"\"\n",
    "    return filter_dataset(data, data.train_mask)\n",
    "\n",
    "\n",
    "def create_test_data_only(data: Data) -> Data:\n",
    "    \"\"\"Create dataset with only test units.\"\"\"\n",
    "    return filter_dataset(data, data.test_mask)\n",
    "\n",
    "import torch \n",
    "\n",
    "\n",
    "full_data_path = '/Users/jason/Documents/Coding Projects/2025_Claude/NetDeconf_main_hao/datasets/exps/BlogCatalog/p=0.0_k=9_seed=194.pt'\n",
    "# full_data_path = 'datasets/exps/Syn/p=0.0_k=0_seed=919.pt'\n",
    "\n",
    "data = torch.load(full_data_path, weights_only=False)\n",
    "create_train_data_only(data)\n",
    "create_train_val_data(data)\n",
    "create_test_data_only(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2874d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Edge Filtering and Edge Attribute Logic\n",
      "\n",
      "=== Test 1: Basic Edge Filtering ===\n",
      "Original graph: 3 units + 2 attrs = 5 nodes\n",
      "Original edges: tensor([[0, 1, 2, 3, 4, 3],\n",
      "        [3, 3, 4, 0, 1, 2]])\n",
      "Original edge_attr: tensor([1., 2., 3., 1., 3., 2.])\n",
      "Unit mask: tensor([ True, False,  True]) (keep units 0, 2)\n",
      "\n",
      "Filtered edges: tensor([[0, 1, 2, 2],\n",
      "        [2, 3, 0, 1]])\n",
      "Filtered edge_attr: tensor([1., 3., 1., 2.])\n",
      "Edge mask: tensor([ True, False,  True,  True, False,  True])\n",
      "Expected edges: tensor([[0, 1, 2, 3, 2],\n",
      "        [2, 3, 0, 1, 1]])\n",
      "Match: False\n",
      "\n",
      "=== Test 2: No Edges Case ===\n",
      "Original: no edges, mask=tensor([ True, False])\n",
      "Result: edges=tensor([], size=(2, 0), dtype=torch.int64), attrs=tensor([])\n",
      "Shapes: edges=torch.Size([2, 0]), attrs=torch.Size([0])\n",
      "\n",
      "=== Test 3: Keep All Units ===\n",
      "Original: edges=tensor([[0, 1, 2, 3],\n",
      "        [2, 3, 0, 1]]), mask=tensor([True, True])\n",
      "Result: edges=tensor([[0, 1, 2, 3],\n",
      "        [2, 3, 0, 1]]), attrs=tensor([5., 6., 5., 6.])\n",
      "Expected: tensor([[0, 1, 2, 3],\n",
      "        [2, 3, 0, 1]])\n",
      "Match: True\n",
      "\n",
      "=== Test 4: Complex Graph ===\n",
      "Original graph: 4 units + 3 attrs\n",
      "Original edges: tensor([[0, 0, 1, 2, 2, 3, 4, 5, 6, 5],\n",
      "        [4, 5, 4, 5, 6, 6, 0, 0, 2, 2]])\n",
      "Original edge_attr: tensor([1.1000, 1.2000, 2.1000, 3.1000, 3.2000, 4.1000, 1.1000, 1.2000, 3.2000,\n",
      "        3.1000])\n",
      "Unit mask: tensor([ True, False,  True,  True]) (remove unit 1)\n",
      "\n",
      "Filtered edges: tensor([[0, 0, 1, 1, 2, 3, 4, 5, 4],\n",
      "        [3, 4, 4, 5, 5, 0, 0, 1, 1]])\n",
      "Filtered edge_attr: tensor([1.1000, 1.2000, 3.1000, 3.2000, 4.1000, 1.1000, 1.2000, 3.2000, 3.1000])\n",
      "Edge mask: tensor([ True,  True, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "\n",
      "Manual verification:\n",
      "  Edge 0: tensor([0, 4]) -> tensor([0, 3]) (attr: 1.100000023841858 -> 1.100000023841858)\n",
      "  Edge 1: tensor([0, 5]) -> tensor([0, 4]) (attr: 1.2000000476837158 -> 1.2000000476837158)\n",
      "  Edge 3: tensor([2, 5]) -> tensor([1, 4]) (attr: 3.0999999046325684 -> 3.0999999046325684)\n",
      "  Edge 4: tensor([2, 6]) -> tensor([1, 5]) (attr: 3.200000047683716 -> 3.200000047683716)\n",
      "  Edge 5: tensor([3, 6]) -> tensor([2, 5]) (attr: 4.099999904632568 -> 4.099999904632568)\n",
      "  Edge 6: tensor([4, 0]) -> tensor([3, 0]) (attr: 1.100000023841858 -> 1.100000023841858)\n",
      "  Edge 7: tensor([5, 0]) -> tensor([4, 0]) (attr: 1.2000000476837158 -> 1.2000000476837158)\n",
      "  Edge 8: tensor([6, 2]) -> tensor([5, 1]) (attr: 3.200000047683716 -> 3.200000047683716)\n",
      "  Edge 9: tensor([5, 2]) -> tensor([4, 1]) (attr: 3.0999999046325684 -> 3.0999999046325684)\n",
      "\n",
      "=== Test 5: Edge Attribute Consistency ===\n",
      "Original: 5 edges\n",
      "Edge values: tensor([10., 20., 30., 10., 30.])\n",
      "Mask: tensor([False,  True,  True])\n",
      "Filtered: 4 edges\n",
      "Filtered values: tensor([20., 30., 10., 30.])\n",
      "âœ… Edge count matches attribute count\n",
      "\n",
      "Edge-by-edge verification:\n",
      "  Edge 0: 0 -> 3, value: 20.0\n",
      "  Edge 1: 1 -> 2, value: 30.0\n",
      "  Edge 2: 2 -> 0, value: 10.0\n",
      "  Edge 3: 3 -> 1, value: 30.0\n",
      "\n",
      "âœ… All tests completed!\n",
      "\n",
      "=== Example Integration ===\n",
      "Original data: 3 units, 2 attrs\n",
      "Original edges: tensor([[0, 1, 2, 3, 4],\n",
      "        [3, 4, 3, 0, 1]])\n",
      "Original edge_attr: tensor([1., 2., 3., 1., 2.])\n",
      "\n",
      "Filtered data:\n",
      "Filtered edges: tensor([[0, 1, 2],\n",
      "        [2, 2, 0]])\n",
      "Filtered edge_attr: tensor([1., 3., 1.])\n",
      "Edge count consistency: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "def filter_and_remap_edges(edge_index, unit_mask, n_units, n_attrs):\n",
    "    \"\"\"\n",
    "    Filter and remap edges in bipartite graph (units <-> attributes).\n",
    "    \n",
    "    Args:\n",
    "        edge_index: torch.Tensor of shape [2, E] \n",
    "        unit_mask: torch.Tensor of shape [n_units] with boolean values for units to keep\n",
    "        n_units: Original number of units\n",
    "        n_attrs: Number of attributes (unchanged)\n",
    "    \n",
    "    Returns:\n",
    "        new_edge_index: torch.Tensor with filtered and remapped edges\n",
    "    \"\"\"\n",
    "    # Create mapping for unit nodes (0 to n_units-1)\n",
    "    unit_mapping = torch.cumsum(unit_mask, dim=0) - 1\n",
    "    unit_mapping[~unit_mask] = -1\n",
    "    \n",
    "    # Create mapping for attribute nodes (n_units to n_units+n_attrs-1)\n",
    "    # Attribute indices need to be shifted down by the number of removed units\n",
    "    n_units_kept = unit_mask.sum().item()\n",
    "    attr_mapping = torch.arange(n_attrs) + n_units_kept  # New attribute indices\n",
    "    \n",
    "    # Create full node mapping\n",
    "    full_mapping = torch.full((n_units + n_attrs,), -1, dtype=torch.long)\n",
    "    full_mapping[:n_units] = unit_mapping\n",
    "    full_mapping[n_units:] = attr_mapping\n",
    "    \n",
    "    # Filter edges: keep only edges involving kept units\n",
    "    unit_nodes_in_edges = edge_index[0] < n_units  # Source is unit\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units  # Source is attribute\n",
    "    \n",
    "    # For unit->attr edges: keep if unit is in mask\n",
    "    unit_to_attr = unit_nodes_in_edges & unit_mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    # For attr->unit edges: keep if target unit is in mask  \n",
    "    attr_to_unit = attr_nodes_in_edges & unit_mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    \n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    \n",
    "    # Apply mapping to filtered edges\n",
    "    filtered_edges = edge_index[:, edge_mask]\n",
    "    new_edge_index = full_mapping[filtered_edges]\n",
    "    \n",
    "    return new_edge_index\n",
    "\n",
    "\n",
    "def test_edge_filtering_basic():\n",
    "    \"\"\"Test 1: Basic functionality with simple bipartite graph\"\"\"\n",
    "    print(\"=== Test 1: Basic Edge Filtering ===\")\n",
    "    \n",
    "    # Setup: 3 units, 2 attributes (total 5 nodes)\n",
    "    n_units, n_attrs = 3, 2\n",
    "    \n",
    "    # Create bipartite edges: units (0,1,2) <-> attributes (3,4)\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3, 4, 3],  # sources: unit0->attr0, unit1->attr0, unit2->attr1, attr0->unit0, attr1->unit1, attr0->unit2\n",
    "        [3, 3, 4, 0, 1, 2]   # targets\n",
    "    ])\n",
    "    \n",
    "    # Edge attributes (values for each edge)\n",
    "    edge_attr = torch.tensor([1.0, 2.0, 3.0, 1.0, 3.0, 2.0])  # Bidirectional edges have same values\n",
    "    \n",
    "    # Keep units 0 and 2 (remove unit 1)\n",
    "    mask = torch.tensor([True, False, True])\n",
    "    \n",
    "    print(f\"Original graph: {n_units} units + {n_attrs} attrs = {n_units + n_attrs} nodes\")\n",
    "    print(f\"Original edges: {edge_index}\")\n",
    "    print(f\"Original edge_attr: {edge_attr}\")\n",
    "    print(f\"Unit mask: {mask} (keep units 0, 2)\")\n",
    "    \n",
    "    # Apply filtering\n",
    "    new_edge_index = filter_and_remap_edges(edge_index, mask, n_units, n_attrs)\n",
    "    \n",
    "    # Filter edge attributes using the same logic\n",
    "    unit_nodes_in_edges = edge_index[0] < n_units\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units\n",
    "    \n",
    "    unit_to_attr = unit_nodes_in_edges & mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    attr_to_unit = attr_nodes_in_edges & mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    \n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    new_edge_attr = edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"\\nFiltered edges: {new_edge_index}\")\n",
    "    print(f\"Filtered edge_attr: {new_edge_attr}\")\n",
    "    print(f\"Edge mask: {edge_mask}\")\n",
    "    \n",
    "    # Expected result:\n",
    "    # - Keep edges involving units 0 and 2\n",
    "    # - Unit 0 -> Unit 0 (remapped), Unit 2 -> Unit 1 (remapped)\n",
    "    # - Attributes 3,4 -> 2,3 (remapped)\n",
    "    expected_edges = torch.tensor([\n",
    "        [0, 1, 2, 3, 2],  # unit0->attr0, unit2->attr1, attr0->unit0, attr1->unit2, attr0->unit1\n",
    "        [2, 3, 0, 1, 1]\n",
    "    ])\n",
    "    \n",
    "    print(f\"Expected edges: {expected_edges}\")\n",
    "    print(f\"Match: {torch.equal(new_edge_index, expected_edges)}\")\n",
    "    \n",
    "\n",
    "def test_edge_filtering_no_edges():\n",
    "    \"\"\"Test 2: Edge case with no edges\"\"\"\n",
    "    print(\"\\n=== Test 2: No Edges Case ===\")\n",
    "    \n",
    "    n_units, n_attrs = 2, 2\n",
    "    edge_index = torch.zeros((2, 0), dtype=torch.long)  # No edges\n",
    "    edge_attr = torch.zeros(0)\n",
    "    mask = torch.tensor([True, False])\n",
    "    \n",
    "    print(f\"Original: no edges, mask={mask}\")\n",
    "    \n",
    "    new_edge_index = filter_and_remap_edges(edge_index, mask, n_units, n_attrs)\n",
    "    \n",
    "    unit_nodes_in_edges = edge_index[0] < n_units\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units\n",
    "    unit_to_attr = unit_nodes_in_edges & mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    attr_to_unit = attr_nodes_in_edges & mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    new_edge_attr = edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"Result: edges={new_edge_index}, attrs={new_edge_attr}\")\n",
    "    print(f\"Shapes: edges={new_edge_index.shape}, attrs={new_edge_attr.shape}\")\n",
    "\n",
    "\n",
    "def test_edge_filtering_keep_all():\n",
    "    \"\"\"Test 3: Keep all units\"\"\"\n",
    "    print(\"\\n=== Test 3: Keep All Units ===\")\n",
    "    \n",
    "    n_units, n_attrs = 2, 2\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3],  # unit0->attr0, unit1->attr1, attr0->unit0, attr1->unit1\n",
    "        [2, 3, 0, 1]\n",
    "    ])\n",
    "    edge_attr = torch.tensor([5.0, 6.0, 5.0, 6.0])\n",
    "    mask = torch.tensor([True, True])  # Keep all units\n",
    "    \n",
    "    print(f\"Original: edges={edge_index}, mask={mask}\")\n",
    "    \n",
    "    new_edge_index = filter_and_remap_edges(edge_index, mask, n_units, n_attrs)\n",
    "    \n",
    "    unit_nodes_in_edges = edge_index[0] < n_units\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units\n",
    "    unit_to_attr = unit_nodes_in_edges & mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    attr_to_unit = attr_nodes_in_edges & mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    new_edge_attr = edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"Result: edges={new_edge_index}, attrs={new_edge_attr}\")\n",
    "    \n",
    "    # Should be identical (just attribute indices shifted)\n",
    "    expected_edges = torch.tensor([\n",
    "        [0, 1, 2, 3],  # Same structure but attrs now at indices 2,3\n",
    "        [2, 3, 0, 1]\n",
    "    ])\n",
    "    print(f\"Expected: {expected_edges}\")\n",
    "    print(f\"Match: {torch.equal(new_edge_index, expected_edges)}\")\n",
    "\n",
    "\n",
    "def test_edge_filtering_complex():\n",
    "    \"\"\"Test 4: More complex graph with multiple connections\"\"\"\n",
    "    print(\"\\n=== Test 4: Complex Graph ===\")\n",
    "    \n",
    "    n_units, n_attrs = 4, 3\n",
    "    \n",
    "    # Create a more complex bipartite graph\n",
    "    # Units 0,1,2,3 connect to attributes 4,5,6\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 0, 1, 2, 2, 3, 4, 5, 6, 5],  # Various unit->attr and attr->unit connections\n",
    "        [4, 5, 4, 5, 6, 6, 0, 0, 2, 2]\n",
    "    ])\n",
    "    edge_attr = torch.tensor([1.1, 1.2, 2.1, 3.1, 3.2, 4.1, 1.1, 1.2, 3.2, 3.1])\n",
    "    \n",
    "    # Keep units 0, 2, 3 (remove unit 1)\n",
    "    mask = torch.tensor([True, False, True, True])\n",
    "    \n",
    "    print(f\"Original graph: {n_units} units + {n_attrs} attrs\")\n",
    "    print(f\"Original edges: {edge_index}\")\n",
    "    print(f\"Original edge_attr: {edge_attr}\")\n",
    "    print(f\"Unit mask: {mask} (remove unit 1)\")\n",
    "    \n",
    "    new_edge_index = filter_and_remap_edges(edge_index, mask, n_units, n_attrs)\n",
    "    \n",
    "    unit_nodes_in_edges = edge_index[0] < n_units\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units\n",
    "    unit_to_attr = unit_nodes_in_edges & mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    attr_to_unit = attr_nodes_in_edges & mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    new_edge_attr = edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"\\nFiltered edges: {new_edge_index}\")\n",
    "    print(f\"Filtered edge_attr: {new_edge_attr}\")\n",
    "    print(f\"Edge mask: {edge_mask}\")\n",
    "    \n",
    "    # Manual verification\n",
    "    print(\"\\nManual verification:\")\n",
    "    for i, keep in enumerate(edge_mask):\n",
    "        if keep:\n",
    "            orig_edge = edge_index[:, i]\n",
    "            new_edge = new_edge_index[:, edge_mask[:i+1].sum()-1] if edge_mask[:i+1].sum() > 0 else None\n",
    "            print(f\"  Edge {i}: {orig_edge} -> {new_edge} (attr: {edge_attr[i]} -> {new_edge_attr[edge_mask[:i+1].sum()-1] if edge_mask[:i+1].sum() > 0 else 'N/A'})\")\n",
    "\n",
    "\n",
    "def test_edge_attr_consistency():\n",
    "    \"\"\"Test 5: Verify edge_attr filtering matches edge_index filtering\"\"\"\n",
    "    print(\"\\n=== Test 5: Edge Attribute Consistency ===\")\n",
    "    \n",
    "    n_units, n_attrs = 3, 2\n",
    "    edge_index = torch.tensor([\n",
    "        [0, 1, 2, 3, 4],\n",
    "        [3, 4, 3, 1, 2]\n",
    "    ])\n",
    "    edge_attr = torch.tensor([10.0, 20.0, 30.0, 10.0, 30.0])\n",
    "    mask = torch.tensor([False, True, True])  # Keep units 1, 2\n",
    "    \n",
    "    print(f\"Original: {edge_index.shape[1]} edges\")\n",
    "    print(f\"Edge values: {edge_attr}\")\n",
    "    print(f\"Mask: {mask}\")\n",
    "    \n",
    "    new_edge_index = filter_and_remap_edges(edge_index, mask, n_units, n_attrs)\n",
    "    \n",
    "    # Apply the same filtering logic to edge attributes\n",
    "    unit_nodes_in_edges = edge_index[0] < n_units\n",
    "    attr_nodes_in_edges = edge_index[0] >= n_units\n",
    "    unit_to_attr = unit_nodes_in_edges & mask[edge_index[0].clamp(max=n_units-1)]\n",
    "    attr_to_unit = attr_nodes_in_edges & mask[edge_index[1].clamp(max=n_units-1)]\n",
    "    edge_mask = unit_to_attr | attr_to_unit\n",
    "    new_edge_attr = edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"Filtered: {new_edge_index.shape[1]} edges\")\n",
    "    print(f\"Filtered values: {new_edge_attr}\")\n",
    "    \n",
    "    # Verify same number of edges and attributes\n",
    "    assert new_edge_index.shape[1] == new_edge_attr.shape[0], \\\n",
    "        f\"Mismatch: {new_edge_index.shape[1]} edges vs {new_edge_attr.shape[0]} attributes\"\n",
    "    \n",
    "    print(\"âœ… Edge count matches attribute count\")\n",
    "    \n",
    "    # Verify edge attribute values make sense\n",
    "    print(\"\\nEdge-by-edge verification:\")\n",
    "    for i in range(new_edge_index.shape[1]):\n",
    "        edge = new_edge_index[:, i]\n",
    "        attr_val = new_edge_attr[i]\n",
    "        print(f\"  Edge {i}: {edge[0]} -> {edge[1]}, value: {attr_val}\")\n",
    "\n",
    "\n",
    "def run_comprehensive_tests():\n",
    "    \"\"\"Run all tests\"\"\"\n",
    "    print(\"ğŸ§ª Testing Edge Filtering and Edge Attribute Logic\\n\")\n",
    "    \n",
    "    test_edge_filtering_basic()\n",
    "    test_edge_filtering_no_edges()\n",
    "    test_edge_filtering_keep_all()\n",
    "    test_edge_filtering_complex()\n",
    "    test_edge_attr_consistency()\n",
    "    \n",
    "    print(\"\\nâœ… All tests completed!\")\n",
    "\n",
    "\n",
    "# Example of how to use this in your actual filtering function\n",
    "def example_usage():\n",
    "    \"\"\"Example showing how this integrates with your filter_dataset function\"\"\"\n",
    "    print(\"\\n=== Example Integration ===\")\n",
    "    \n",
    "    # Simulate a data object\n",
    "    class MockData:\n",
    "        def __init__(self):\n",
    "            self.n_units = 3\n",
    "            self.n_attrs = 2\n",
    "            self.edge_index = torch.tensor([\n",
    "                [0, 1, 2, 3, 4],\n",
    "                [3, 4, 3, 0, 1]\n",
    "            ])\n",
    "            self.edge_attr = torch.tensor([1.0, 2.0, 3.0, 1.0, 2.0])\n",
    "    \n",
    "    data = MockData()\n",
    "    mask = torch.tensor([True, False, True])  # Keep units 0, 2\n",
    "    \n",
    "    print(f\"Original data: {data.n_units} units, {data.n_attrs} attrs\")\n",
    "    print(f\"Original edges: {data.edge_index}\")\n",
    "    print(f\"Original edge_attr: {data.edge_attr}\")\n",
    "    \n",
    "    # Apply the filtering logic from your function\n",
    "    train_data = MockData()  # New filtered data object\n",
    "    \n",
    "    # Filter and remap edges\n",
    "    train_data.edge_index = filter_and_remap_edges(\n",
    "        data.edge_index, mask, data.n_units, data.n_attrs\n",
    "    )\n",
    "    \n",
    "    # Filter edge attributes based on which edges were kept\n",
    "    if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n",
    "        # Need to determine which edges were kept\n",
    "        unit_nodes_in_edges = data.edge_index[0] < data.n_units\n",
    "        attr_nodes_in_edges = data.edge_index[0] >= data.n_units\n",
    "        \n",
    "        unit_to_attr = unit_nodes_in_edges & mask[data.edge_index[0].clamp(max=data.n_units-1)]\n",
    "        attr_to_unit = attr_nodes_in_edges & mask[data.edge_index[1].clamp(max=data.n_units-1)]\n",
    "        \n",
    "        edge_mask = unit_to_attr | attr_to_unit\n",
    "        train_data.edge_attr = data.edge_attr[edge_mask]\n",
    "    \n",
    "    print(f\"\\nFiltered data:\")\n",
    "    print(f\"Filtered edges: {train_data.edge_index}\")\n",
    "    print(f\"Filtered edge_attr: {train_data.edge_attr}\")\n",
    "    print(f\"Edge count consistency: {train_data.edge_index.shape[1] == train_data.edge_attr.shape[0]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_comprehensive_tests()\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
